{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Dataset Loader\n",
    "'''\n",
    "class AksaraBali(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, setSize, transform=None, height=105, width=105):        \n",
    "        csvFile = pd.read_csv(csv_file, header=None)\n",
    "        self.csv_file = csvFile\n",
    "        self.root_dir = root_dir\n",
    "        self.setSize = setSize\n",
    "        self.transform = transform\n",
    "        self.categories = csvFile[2].unique()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.setSize\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img1 = None\n",
    "        img2 = None\n",
    "        label = None\n",
    "\n",
    "        if index % 2 == 0:\n",
    "            category = random.choice(self.categories)\n",
    "            img1_path = os.path.join(self.root_dir, random.choice(self.csv_file[self.csv_file[2]==category][0].values))\n",
    "            img2_path = os.path.join(self.root_dir, random.choice(self.csv_file[self.csv_file[2]==category][0].values))\n",
    "            img1 = Image.open(img1_path).resize((self.height, self.width))\n",
    "            img2 = Image.open(img2_path).resize((self.height, self.width))\n",
    "            label = 1.0\n",
    "\n",
    "        else:\n",
    "            category1, category2 = random.choice(self.categories), random.choice(self.categories)\n",
    "            img1_path = os.path.join(self.root_dir, random.choice(self.csv_file[self.csv_file[2]==category1][0].values))\n",
    "            img2_path = os.path.join(self.root_dir, random.choice(self.csv_file[self.csv_file[2]==category2][0].values))\n",
    "            while img1_path == img2_path:\n",
    "                img2_path = os.path.join(self.root_dir, random.choice(self.csv_file[self.csv_file[2]==category2][0].values))\n",
    "            img1 = Image.open(img1_path).resize((self.height, self.width))\n",
    "            img2 = Image.open(img2_path).resize((self.height, self.width))\n",
    "            label = 0.0\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        return img1, img2, torch.from_numpy(np.array([label], dtype=np.float32))\n",
    "\n",
    "class NWayOneShotEvalSet(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, setSize, numWay, transform=None,height=105, width=105):\n",
    "        self.csv_file = pd.read_csv(csv_file, header=None)\n",
    "        self.root_dir = root_dir\n",
    "        self.setSize = setSize\n",
    "        self.transform = transform\n",
    "        self.categories = self.csv_file[2].unique()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.numWay = numWay\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.setSize\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # find one main image\n",
    "        category =  random.choice(self.categories) # find main class label\n",
    "        imgDir = os.path.join(self.root_dir, random.choice(self.csv_file[self.csv_file[2]==category][0].values)) # find random img in main class label\n",
    "        mainImg = Image.open(imgDir).resize((self.height, self.width)) # open img\n",
    "        if self.transform:\n",
    "            mainImg = self.transform(mainImg)\n",
    "        \n",
    "        # find n numbers of distinct images, 1 in the same set as the main\n",
    "        testSet = []\n",
    "        label = np.random.randint(self.numWay)\n",
    "        for i in range(self.numWay):\n",
    "            if i == label:\n",
    "                imgDirTest = os.path.join(self.root_dir, random.choice(self.csv_file[self.csv_file[2]==category][0].values))\n",
    "                while imgDir == imgDirTest:\n",
    "                    imgDirTest = os.path.join(self.root_dir, random.choice(self.csv_file[self.csv_file[2]==category][0].values))\n",
    "            else:\n",
    "                categoryTest = random.choice(self.categories)\n",
    "                while category == categoryTest:\n",
    "                    categoryTest = random.choice(self.categories)\n",
    "                imgDirTest = os.path.join(self.root_dir, random.choice(self.csv_file[self.csv_file[2]==categoryTest][0].values))\n",
    "            testImg = Image.open(imgDirTest).resize((self.height, self.width))\n",
    "            if self.transform:\n",
    "                testImg = self.transform(testImg)\n",
    "            testSet.append(testImg)\n",
    "        \n",
    "        return mainImg, testSet, torch.from_numpy(np.array([label], dtype= int))        \n",
    "    \n",
    "'''\n",
    "Model\n",
    "'''\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # conv2d(input_channels, output_channels, kernel_size)\n",
    "        self.conv1 = nn.Conv2d(3, 64, 10)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 7)\n",
    "        self.conv3 = nn.Conv2d(128, 128, 4)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 4)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
    "        self.fcOut = nn.Linear(4096, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def convs(self, x):\n",
    "        # out_dim = in_dim - kernel_size + 1\n",
    "        # 1, 105, 105\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        # 64, 96, 96\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        # 64, 48, 48\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        # 128, 42, 42\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        # 128, 21, 21\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        # 128, 18, 18\n",
    "        x = F.max_pool2d(x, (2,2))\n",
    "        # 128, 9, 9\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        # 256, 6, 6\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.convs(x1)\n",
    "        x1 = x1.view(-1, 256 * 6 * 6)\n",
    "        x1 = self.sigmoid(self.fc1(x1))\n",
    "        x2 = self.convs(x2)\n",
    "        x2 = x2.view(-1, 256 * 6 * 6)\n",
    "        x2 = self.sigmoid(self.fc1(x2))\n",
    "        x = torch.abs(x1 - x2)\n",
    "        x = self.fcOut(x)\n",
    "        return x\n",
    "\n",
    "def count_parameters(model):\n",
    "    temp = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'The model architecture :\\n\\n', model)\n",
    "    print(f'\\nThe model has {temp:,} trainable parameters')\n",
    "    \n",
    "'''\n",
    "Train and Eval Setting\n",
    "'''\n",
    "    \n",
    "def train(model, train_loader, val_loader, num_epochs, criterion, save_name):\n",
    "    best_val_loss = float(\"Inf\")\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    cur_step = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        print(\"Starting epoch \" + str(epoch+1))\n",
    "        for img1, img2, labels in train_loader:\n",
    "            \n",
    "            # Forward\n",
    "            img1 = img1.to(device)\n",
    "            img2 = img2.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(img1, img2)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        val_running_loss = 0.0\n",
    "        \n",
    "        # check validation loss after every epoch\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for img1, img2, labels in val_loader:\n",
    "                img1 = img1.to(device)\n",
    "                img2 = img2.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(img1, img2)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_running_loss += loss.item()\n",
    "        avg_val_loss = val_running_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        print('Epoch [{}/{}], Train Loss : {:.4f}, Valid Loss: {:.8f}'.format(epoch+1, num_epochs, avg_train_loss, avg_val_loss))\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            save_checkpoint(save_name, model, optimizer, best_val_loss)\n",
    "    print('Finished Training')\n",
    "    return train_losses, val_losses\n",
    "\n",
    "def eval(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        print('Starting Iteration')\n",
    "        count = 0\n",
    "        for mainImg, imgSets, label in test_loader:\n",
    "            mainImg = mainImg.to(device)\n",
    "            predVal = 0\n",
    "            pred = -1\n",
    "            for i, testImg in enumerate(imgSets):\n",
    "                testImg = testImg.to(device)\n",
    "                output = model(mainImg, testImg)\n",
    "                if output > predVal:\n",
    "                    pred = i\n",
    "                    predVal = output\n",
    "            label = label.to(device)\n",
    "            if pred == label:\n",
    "                correct += 1\n",
    "            count += 1\n",
    "            if count % 20 == 0:\n",
    "                print(f'Current count is : {count}')\n",
    "                print(f'Accuracy on n way : {correct/count}')\n",
    "\n",
    "'''\n",
    "Model Checkpoints\n",
    "'''\n",
    "def save_checkpoint(save_path, model, optimizer, val_loss):\n",
    "    if save_path==None:\n",
    "        return\n",
    "    save_path = save_path\n",
    "    state_dict = {'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'val_loss': val_loss}\n",
    "    torch.save(state_dict, save_path)\n",
    "\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "def load_checkpoint(model, optimizer, save_path):\n",
    "    # save_path = f'siameseNet-batchnorm50.pt'\n",
    "    state_dict = torch.load(save_path)\n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    val_loss = state_dict['val_loss']\n",
    "    print(f'Model loaded from <== {save_path}')\n",
    "\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train DataLoad\n",
    "'''\n",
    "TrainRoot_dir = '../data/Train Original/img/'\n",
    "TrainCsv_file = '../data/Train Original/trainOri_label.csv'\n",
    "\n",
    "dataSize = 11710\n",
    "TRAIN_PCT = 0.8\n",
    "train_size = int(dataSize * TRAIN_PCT)\n",
    "val_size = dataSize - train_size\n",
    "\n",
    "tranformations = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "aksaraDataset = AksaraBali(TrainCsv_file, TrainRoot_dir, dataSize, tranformations)\n",
    "train_set, val_set = random_split(aksaraDataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=1, shuffle=True)\n",
    "\n",
    "print('Training data succesfully loaded')\n",
    "\n",
    "\n",
    "'''\n",
    "Test DataLoad\n",
    "'''\n",
    "TestRoot_dir = '../data/Test/img/'\n",
    "TestCsv_file = '../data/Test/test_label.csv'\n",
    "\n",
    "testSize = 7673\n",
    "numWay = 132\n",
    "\n",
    "test_set = NWayOneShotEvalSet(TestCsv_file, TestRoot_dir, testSize, numWay, tranformations)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=True)\n",
    "\n",
    "print('Testing data succesfully loaded')\n",
    "\n",
    "\n",
    "'''\n",
    "Model Compilation\n",
    "'''\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "siameseBaseLine = Net()\n",
    "siameseBaseLine = siameseBaseLine.to(device)\n",
    "\n",
    "print(f'Model succecfully created and loaded to GPU')\n",
    "\n",
    "'''\n",
    "Model Training\n",
    "'''\n",
    "optimizer = optim.Adam(siameseBaseLine.parameters(), lr=0.0001)\n",
    "num_epochs = 100\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "save_path = 'test.pt'\n",
    "train_losses, val_losses = train(siameseBaseLine, train_loader, val_loader, num_epochs, criterion, save_path)\n",
    "\n",
    "'''\n",
    "Model Validation\n",
    "'''\n",
    "load_model = Net().to(device)\n",
    "load_optimizer = optim.Adam(load_model.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 10\n",
    "eval_every = 1000\n",
    "total_step = len(train_loader)*num_epochs\n",
    "best_val_loss = load_checkpoint(load_model, load_optimizer, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}